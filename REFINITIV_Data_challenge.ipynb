{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE,TIME,UNIQUE_STORY_INDEX,EVENT_TYPE,PNAC,STORY_DATE_TIME,TAKE_DATE_TIME,HEADLINE_ALERT_TEXT,ACCUMULATED_STORY_TEXT,TAKE_TEXT,PRODUCTS,TOPICS,RELATED_RICS,NAMED_ITEMS,HEADLINE_SUBTYPE,STORY_TYPE,TABULAR_FLAG,ATTRIBUTION,LANGUAGE\r\n"
     ]
    }
   ],
   "source": [
    "!head -1 rna002_RTRS_2017_11_29.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data in CSV format with comma separator & include HEADER\n",
    "- This can be load by spark sql (for production) and pandas (for experiement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-06-01,00:00:51.439,\"20130601000050nL2N0EC22A\",\"STORY_TAKE_OVERWRITE\",\"nL2N0EC22A\",\"2013-06-01 00:00:50\",\"\",\"ONU pede à Grã-Bretanha que investigue torturas no Iraque e Afeganistão\",\"\",\"    GENEBRA, 31 Mai (Reuters) - O Comitê Contra a Tortura da ONU \r\n",
      "pediu nesta sexta-feira à Grã-Bretanha que amplie e acelere suas \r\n",
      "investigações sobre supostos abusos cometidos por soldados \r\n",
      "britânicos contra detentos no Iraque e no Afeganistão e que puna \r\n",
      "os responsáveis. \r\n",
      "    \"\"O Comitê Contra a Tortura está profundamente preocupado com \r\n",
      "o crescente número de acusações sérias de torturas e maus \r\n",
      "tratos, inclusive por cumplicidade, como resultado das \r\n",
      "intervenções militares estatais no Iraque e Afeganistão\"\", disse \r\n",
      "o órgão da ONU. \r\n",
      "    Seus dez especialistas independentes apresentaram suas \r\n",
      "conclusões após examinarem a atuação da Grã-Bretanha no \r\n",
      "cumprimento das leis internacionais que proíbem a tortura. \r\n",
      "    Muitos iraquianos dizem ter sido torturados por soldados da \r\n",
      "ocupação britânica entre 2003 e 2009, mas Londres por enquanto \r\n",
      "resiste em promover um inquérito público completo que avalie a \r\n",
      "dimensão desse problema e estabeleça responsabilidades, \r\n",
      "inclusive para líderes políticos e militares, segundo o comitê \r\n",
      "da Organização das Nações Unidas (ONU). \r\n",
      "    (Reportagem de Stephanie Nebehay) \r\n",
      "    ((Tradução Redação São Paulo; +5511 5644-7731)) \r\n",
      "    REUTERS BM \r\n",
      "\",\"BRS DNP\",\"BR GB PIA GEN EMRG AMERS LATAM WEU EUROP LPT RTRS\",\"\",\"\",\"\",\"S\",\"FALSE\",\"RTRS\",\"PT\"\r\n"
     ]
    }
   ],
   "source": [
    "!head -40 rna002_RTRS_2017_11_29.csv | tail -23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data contain multiple lines in one column\n",
    "- Contain multiple double quote \"\" which not the escape character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Asumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - not escapse double quote \"\" is meaningless which will not break the text content structure => can be remove\n",
    " - After remove meaningless double quote & standadize the text column which only be wraped inside a proper double quote {open} and {close}, for example: \"ABCDD    \\n \\n ADBC\"\n",
    " - Finally, just need to handle multiLine column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Flow to clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Simple Spark job to standadize the text column => store the data to immidiate File\n",
    " 2. Handle multiple line file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_hdfs_file(sc, path):\n",
    "    if sc is None:\n",
    "        print('Spark Context is None')\n",
    "        return\n",
    "    \n",
    "    URI = sc._gateway.jvm.java.net.URI\n",
    "    Path = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    FileSystem = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    " \n",
    "    fs = FileSystem.get(URI(path), sc._jsc.hadoopConfiguration())\n",
    "    if fs.exists(Path(path)):\n",
    "        return fs.delete(Path(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>#1. Filter job</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\\\n",
    "    .setAppName(\"Cleaning Job\")\\\n",
    "    .setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = sc.textFile('rna002_RTRS_2017_11_29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169592"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DATE,TIME,UNIQUE_STORY_INDEX,EVENT_TYPE,PNAC,STORY_DATE_TIME,TAKE_DATE_TIME,HEADLINE_ALERT_TEXT,ACCUMULATED_STORY_TEXT,TAKE_TEXT,PRODUCTS,TOPICS,RELATED_RICS,NAMED_ITEMS,HEADLINE_SUBTYPE,STORY_TYPE,TABULAR_FLAG,ATTRIBUTION,LANGUAGE']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean = raw.filter(lambda x: len(x)>0)\\\n",
    "    .map(lambda x: re.sub(pattern=r'\"\"', string=x, repl=''))\\\n",
    "    .map(lambda x: re.sub(pattern=r'^\",', string=x, repl='@@@\",'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path = 'clean_rna002_RTRS_2017_11_29.csv'\n",
    "delete_hdfs_file(sc, output_path)\n",
    "clean.coalesce(1).saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>#2. Load data job</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SimpleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = spark.read\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .option(\"multiLine\",\"true\")\\\n",
    "    .option(\"quoteMode\",\"ALL\")\\\n",
    "    .option(\"mode\",\"PERMISSIVE\")\\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",\"true\")\\\n",
    "    .option(\"ignoreTrailingWhiteSpace\",\"true\")\\\n",
    "    .option(\"parserLib\",\"UNIVOCITY\")\\\n",
    "    .option(\"escape\",'\\n')\\\n",
    "    .option(\"wholeFile\",\"True\")\\\n",
    "    .csv('clean_rna002_RTRS_2017_11_29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8131"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DATE: timestamp (nullable = true)\n",
      " |-- TIME: string (nullable = true)\n",
      " |-- UNIQUE_STORY_INDEX: string (nullable = true)\n",
      " |-- EVENT_TYPE: string (nullable = true)\n",
      " |-- PNAC: string (nullable = true)\n",
      " |-- STORY_DATE_TIME: timestamp (nullable = true)\n",
      " |-- TAKE_DATE_TIME: timestamp (nullable = true)\n",
      " |-- HEADLINE_ALERT_TEXT: string (nullable = true)\n",
      " |-- ACCUMULATED_STORY_TEXT: string (nullable = true)\n",
      " |-- TAKE_TEXT: string (nullable = true)\n",
      " |-- PRODUCTS: string (nullable = true)\n",
      " |-- TOPICS: string (nullable = true)\n",
      " |-- RELATED_RICS: string (nullable = true)\n",
      " |-- NAMED_ITEMS: string (nullable = true)\n",
      " |-- HEADLINE_SUBTYPE: integer (nullable = true)\n",
      " |-- STORY_TYPE: string (nullable = true)\n",
      " |-- TABULAR_FLAG: boolean (nullable = true)\n",
      " |-- ATTRIBUTION: string (nullable = true)\n",
      " |-- LANGUAGE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert to Pandas DataFrame for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = raw.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8131 entries, 0 to 8130\n",
      "Data columns (total 19 columns):\n",
      "DATE                      8131 non-null datetime64[ns]\n",
      "TIME                      8131 non-null object\n",
      "UNIQUE_STORY_INDEX        8131 non-null object\n",
      "EVENT_TYPE                8131 non-null object\n",
      "PNAC                      8131 non-null object\n",
      "STORY_DATE_TIME           8131 non-null datetime64[ns]\n",
      "TAKE_DATE_TIME            4551 non-null datetime64[ns]\n",
      "HEADLINE_ALERT_TEXT       7176 non-null object\n",
      "ACCUMULATED_STORY_TEXT    376 non-null object\n",
      "TAKE_TEXT                 3579 non-null object\n",
      "PRODUCTS                  7181 non-null object\n",
      "TOPICS                    7181 non-null object\n",
      "RELATED_RICS              1504 non-null object\n",
      "NAMED_ITEMS               1441 non-null object\n",
      "HEADLINE_SUBTYPE          3238 non-null float64\n",
      "STORY_TYPE                7181 non-null object\n",
      "TABULAR_FLAG              7181 non-null object\n",
      "ATTRIBUTION               7181 non-null object\n",
      "LANGUAGE                  7181 non-null object\n",
      "dtypes: datetime64[ns](3), float64(1), object(15)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion\n",
    "- We are easy to see that there are three columns: HEADLINE_ALERT_TEXT, ACCUMULATED_STORY_TEXT, TAKE_TEXT which are contain text content\n",
    "- ACCUMULATED_STORY_TEXT: has very bad quality (just only 376 out of 8181 are non-empty) -> will not consider this colum\n",
    "- HEADLINE_ALERT_TEXT: seems to be title of article\n",
    "- TAKE_TEXT: looks like the content body of article\n",
    "- <b>Will use both of these two columns to extract the trending words</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RTRS    7181\n",
       "NaN      950\n",
       "Name: ATTRIBUTION, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ATTRIBUTION.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1168e0990>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD3CAYAAADi8sSvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168e0450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.LANGUAGE.value_counts(dropna=False).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEST             686\n",
       "ARNS             581\n",
       "FA FB SWF DNP    346\n",
       "KRN DNP          211\n",
       "S                208\n",
       "Name: PRODUCTS, dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.PRODUCTS.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### Asumption\n",
    " - English language is the most popular language here\n",
    " - It will make sense to just look into only English text here in order to extract the trending keywords (and skip for the other languages)\n",
    " - Also filter out 'TEST' products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 19)\n"
     ]
    }
   ],
   "source": [
    "df_en = df[(df.LANGUAGE=='EN')&(df.PRODUCTS!='TEST')]\n",
    "print(df_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty percentage:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                       0.000000\n",
       "TIME                       0.000000\n",
       "UNIQUE_STORY_INDEX         0.000000\n",
       "EVENT_TYPE                 0.000000\n",
       "PNAC                       0.000000\n",
       "STORY_DATE_TIME            0.000000\n",
       "TAKE_DATE_TIME            48.290323\n",
       "HEADLINE_ALERT_TEXT        0.193548\n",
       "ACCUMULATED_STORY_TEXT    96.548387\n",
       "TAKE_TEXT                 51.709677\n",
       "PRODUCTS                   0.000000\n",
       "TOPICS                     0.000000\n",
       "RELATED_RICS              71.677419\n",
       "NAMED_ITEMS               76.548387\n",
       "HEADLINE_SUBTYPE          54.387097\n",
       "STORY_TYPE                 0.000000\n",
       "TABULAR_FLAG               0.000000\n",
       "ATTRIBUTION                0.000000\n",
       "LANGUAGE                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Empty percentage:\")\n",
    "df_en.isnull().sum() * 100.0/len(df_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>HEADLINE_ALERT_TEXT</th>\n",
       "      <th>TAKE_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>01:00:15.218</td>\n",
       "      <td>BOJ: c/a balance &amp; market operations (5/31) -...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>23:33:29.521</td>\n",
       "      <td>SERVICE ALERT - RDF+ Svc- Hazelwood PoP, USA -...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>21:05:03.468</td>\n",
       "      <td>Angelina Jolie makes first public appearance a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>03:07:57.661</td>\n",
       "      <td>*TOP NEWS* Energy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>22:24:56.690</td>\n",
       "      <td>UPDATE 1-Golf-Kuchar moves two ahead at windy ...</td>\n",
       "      <td>* Kuchar takes control with a 70 in gustin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>05:00:21.559</td>\n",
       "      <td>CORRECTED-BRIEF-Mitsubishi to buy Los Grobo Ce...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>18:55:28.021</td>\n",
       "      <td>Three storm chasers among 10 killed by Oklahom...</td>\n",
       "      <td>By Daniel Trotta and Jonathan Allen \\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>04:56:54.921</td>\n",
       "      <td>*TOP NEWS* Asian Companies</td>\n",
       "      <td>For expanded, multimedia Reuters Top News visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>04:03:05.618</td>\n",
       "      <td>TABLE-Details of Indian govt borrowings in 201...</td>\n",
       "      <td>Jun 1 (Reuters) - The Indian government plans ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>12:37:07.250</td>\n",
       "      <td>S.Africa investigates Libyan claims on stashed...</td>\n",
       "      <td>JOHANNESBURG, June 2 (Reuters) - South Afr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE          TIME  \\\n",
       "6019 2013-06-03  01:00:15.218   \n",
       "5452 2013-06-02  23:33:29.521   \n",
       "4788 2013-06-02  21:05:03.468   \n",
       "7157 2013-06-03  03:07:57.661   \n",
       "2490 2013-06-01  22:24:56.690   \n",
       "485  2013-06-01  05:00:21.559   \n",
       "4495 2013-06-02  18:55:28.021   \n",
       "8075 2013-06-03  04:56:54.921   \n",
       "425  2013-06-01  04:03:05.618   \n",
       "3667 2013-06-02  12:37:07.250   \n",
       "\n",
       "                                    HEADLINE_ALERT_TEXT  \\\n",
       "6019   BOJ: c/a balance & market operations (5/31) -...   \n",
       "5452  SERVICE ALERT - RDF+ Svc- Hazelwood PoP, USA -...   \n",
       "4788  Angelina Jolie makes first public appearance a...   \n",
       "7157                                  *TOP NEWS* Energy   \n",
       "2490  UPDATE 1-Golf-Kuchar moves two ahead at windy ...   \n",
       "485   CORRECTED-BRIEF-Mitsubishi to buy Los Grobo Ce...   \n",
       "4495  Three storm chasers among 10 killed by Oklahom...   \n",
       "8075                         *TOP NEWS* Asian Companies   \n",
       "425   TABLE-Details of Indian govt borrowings in 201...   \n",
       "3667  S.Africa investigates Libyan claims on stashed...   \n",
       "\n",
       "                                              TAKE_TEXT  \n",
       "6019                                               None  \n",
       "5452                                               None  \n",
       "4788                                               None  \n",
       "7157                                               None  \n",
       "2490      * Kuchar takes control with a 70 in gustin...  \n",
       "485                                                None  \n",
       "4495      By Daniel Trotta and Jonathan Allen \\n    ...  \n",
       "8075  For expanded, multimedia Reuters Top News visi...  \n",
       "425   Jun 1 (Reuters) - The Indian government plans ...  \n",
       "3667      JOHANNESBURG, June 2 (Reuters) - South Afr...  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en[['DATE', 'TIME', 'HEADLINE_ALERT_TEXT', 'TAKE_TEXT']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, DoubleType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw.registerTempTable('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql='''\n",
    "    select *, \n",
    "        (CASE\n",
    "            WHEN LANGUAGE<>'EN' THEN ''\n",
    "            WHEN PRODUCTS=='TEST' THEN ''\n",
    "            WHEN TAKE_TEXT IS NULL THEN HEADLINE_ALERT_TEXT\n",
    "            ELSE TAKE_TEXT\n",
    "        END) as TEXT_CONTENT\n",
    "    from temp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process text\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    if text is None:\n",
    "        return ''\n",
    "    text=text.lower()\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_process_udf = f.udf(pre_process, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_df = spark.sql(sqlQuery=sql)\\\n",
    "    .select('DATE', 'TIME', 'LANGUAGE', 'PRODUCTS', pre_process_udf('TEXT_CONTENT').alias('TEXT_CONTENT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "|               DATE|        TIME|LANGUAGE|            PRODUCTS|        TEXT_CONTENT|\n",
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "|2013-06-01 00:00:00|00:00:00.704|      EN|             E U CAN|mercator minerals...|\n",
      "|2013-06-01 00:00:00|00:00:00.885|      EN|M D T E C MTL GRO...|s korea says may ...|\n",
      "|2013-06-01 00:00:00|00:00:01.052|    null|                null|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.052|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.055|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.112|      EN|             E U CAN|mercator minerals...|\n",
      "|2013-06-01 00:00:00|00:00:01.201|      EN|M D T E C MTL GRO...|s korea says may ...|\n",
      "|2013-06-01 00:00:00|00:00:01.221|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.221|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.325|    null|                null|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.325|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:01.446|      EN|M D T E C MTL GRO...|s korea says may ...|\n",
      "|2013-06-01 00:00:00|00:00:01.571|      EN|M D T E C MTL GRO...|s korea may avg e...|\n",
      "|2013-06-01 00:00:00|00:00:01.571|      EN|                TEST|                    |\n",
      "|2013-06-01 00:00:00|00:00:15.120|      EN|                 E U|star buffet inc s...|\n",
      "|2013-06-01 00:00:00|00:00:51.385|      PT|             BRS DNP|                    |\n",
      "|2013-06-01 00:00:00|00:00:51.439|      PT|             BRS DNP|                    |\n",
      "|2013-06-01 00:00:00|00:00:52.596|      EN|S Z EMK PSC RNP D...|update golf haas ...|\n",
      "|2013-06-01 00:00:00|00:00:52.675|      EN|S Z EMK PSC RNP D...|haas moves three ...|\n",
      "|2013-06-01 00:00:00|00:01:27.514|      AR|                ARNS|                    |\n",
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using simple NLP technique to extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"TEXT_CONTENT\", outputCol=\"raw\")\n",
    "remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"words\")\n",
    "# hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "# idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv])\n",
    "model = pipeline.fit(text_df)\n",
    "\n",
    "results = model.transform(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DATE: timestamp (nullable = true)\n",
      " |-- TIME: string (nullable = true)\n",
      " |-- LANGUAGE: string (nullable = true)\n",
      " |-- PRODUCTS: string (nullable = true)\n",
      " |-- TEXT_CONTENT: string (nullable = true)\n",
      " |-- raw: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_values_from_vector(vector):\n",
    "    return vector.values.tolist()\n",
    "\n",
    "extract_values_from_vector_udf = f.udf(extract_values_from_vector, ArrayType(DoubleType()))\n",
    "\n",
    "# And use that UDF to get your values\n",
    "word_count = results.select('DATE', 'TIME', 'LANGUAGE', extract_values_from_vector_udf('features').alias('count'), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "|               DATE|        TIME|LANGUAGE|               count|               words|\n",
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "|2013-06-01 00:00:00|00:00:00.704|      EN|[1.0, 1.0, 1.0, 1...|[mercator, minera...|\n",
      "|2013-06-01 00:00:00|00:00:00.885|      EN|[1.0, 1.0, 1.0, 1...|[korea, says, may...|\n",
      "|2013-06-01 00:00:00|00:00:01.052|    null|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.052|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.055|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.112|      EN|[1.0, 1.0, 1.0, 1...|[mercator, minera...|\n",
      "|2013-06-01 00:00:00|00:00:01.201|      EN|[1.0, 1.0, 2.0, 1...|[korea, says, may...|\n",
      "|2013-06-01 00:00:00|00:00:01.221|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.221|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.325|    null|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.325|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:01.446|      EN|[1.0, 1.0, 2.0, 1...|[korea, says, may...|\n",
      "|2013-06-01 00:00:00|00:00:01.571|      EN|[1.0, 1.0, 1.0, 1...|[korea, may, avg,...|\n",
      "|2013-06-01 00:00:00|00:00:01.571|      EN|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:15.120|      EN|[1.0, 1.0, 1.0, 1...|[star, buffet, in...|\n",
      "|2013-06-01 00:00:00|00:00:51.385|      PT|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:51.439|      PT|               [1.0]|                  []|\n",
      "|2013-06-01 00:00:00|00:00:52.596|      EN|[1.0, 1.0, 1.0, 1...|[update, golf, ha...|\n",
      "|2013-06-01 00:00:00|00:00:52.675|      EN|[4.0, 2.0, 2.0, 3...|[haas, moves, thr...|\n",
      "|2013-06-01 00:00:00|00:01:27.514|      AR|               [1.0]|                  []|\n",
      "+-------------------+------------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can zip two columns (count and words) and sort by count to have better look about word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n",
    "sorted_x = sorted(x.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (2, 1)]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_top(count, words, topk=5):\n",
    "    sorted_x = sorted(zip(words, count), key=operator.itemgetter(1), reverse=True)\n",
    "    if topk > 0:\n",
    "        return json.dumps(dict(sorted_x[:topk]))\n",
    "    else:\n",
    "        return json.dumps(dict(sorted_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_top_udf = f.udf(extract_top, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(extract_top(count, words)=u'{\"announces\": 1.0, \"senior\": 1.0, \"management\": 1.0, \"minerals\": 1.0, \"mercator\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"may\": 1.0, \"korea\": 1.0, \"says\": 1.0, \"provisional\": 2.0, \"trade\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"announces\": 1.0, \"senior\": 1.0, \"management\": 1.0, \"minerals\": 1.0, \"mercator\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"may\": 2.0, \"exports\": 1.0, \"korea\": 1.0, \"says\": 1.0, \"pct\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"may\": 2.0, \"imports\": 1.0, \"korea\": 1.0, \"says\": 1.0, \"pct\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"may\": 1.0, \"exports\": 1.0, \"korea\": 1.0, \"avg\": 1.0, \"day\": 2.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"real\": 1.0, \"sells\": 1.0, \"star\": 1.0, \"buffet\": 1.0, \"inc\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"haas\": 1.0, \"memorial\": 1.0, \"golf\": 1.0, \"update\": 1.0, \"takes\": 1.0}'),\n",
       " Row(extract_top(count, words)=u'{\"got\": 8.0, \"dublin\": 7.0, \"yet\": 11.0, \"shot\": 5.0, \"successive\": 6.0}'),\n",
       " Row(extract_top(count, words)=u'{\"\": 1.0}')]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.select(extract_top_udf('count', 'words')).take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "- So here, we can easy to see the frequent word from time to time. However we might need to see the word frequency by time window, for example by hour, day, week ...\n",
    "- We will need to take advantage of DATE, TIME data. \n",
    "- One drawback by using SPARK here is: SPARK is not really convenient to deal with timeseries data and espcially to aggregate data by timewindow. So that we will use Pandas to go a little deep dive (This will only usefor experiment & not production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Spark Dataframe to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_pd = word_count.select('DATE', 'TIME', extract_top_udf('count', 'words', f.lit(-1)).alias('trending')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>00:00:00.704</td>\n",
       "      <td>{\"announces\": 1.0, \"senior\": 1.0, \"management\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>00:00:00.885</td>\n",
       "      <td>{\"korea\": 1.0, \"says\": 1.0, \"may\": 1.0, \"revis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>00:00:01.052</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>00:00:01.052</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>00:00:01.055</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE          TIME                                           trending\n",
       "0 2013-06-01  00:00:00.704  {\"announces\": 1.0, \"senior\": 1.0, \"management\"...\n",
       "1 2013-06-01  00:00:00.885  {\"korea\": 1.0, \"says\": 1.0, \"may\": 1.0, \"revis...\n",
       "2 2013-06-01  00:00:01.052                                                 {}\n",
       "3 2013-06-01  00:00:01.052                                                 {}\n",
       "4 2013-06-01  00:00:01.055                                                 {}"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE        datetime64[ns]\n",
       "TIME                object\n",
       "trending            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_pd['DATE_TIME'] = word_count_pd.DATE.dt.strftime('%Y-%m-%d') + ' ' + word_count_pd.TIME\n",
    "word_count_pd['DATE_TIME'] = pd.to_datetime(word_count_pd['DATE_TIME'])\n",
    "word_count_pd = word_count_pd.set_index('DATE_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_freq(x, topK=10):\n",
    "    super_dict = {}\n",
    "    dicts = x.map(lambda y: json.loads(y)).values\n",
    "    for d in dicts:\n",
    "        for k, v in d.iteritems():  # d.items() in Python 3+\n",
    "            if k:\n",
    "                super_dict.setdefault(k, []).append(v)\n",
    "                \n",
    "    for k, v in super_dict.iteritems():\n",
    "        super_dict[k] = sum(v)\n",
    "        \n",
    "    sorted_x = sorted(super_dict.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_x[:topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-01 00:00:00</th>\n",
       "      <td>[(expanded, 364.0), (reuters, 229.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 04:00:00</th>\n",
       "      <td>[(reuters, 105.0), (money, 72.0), (north, 63.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 08:00:00</th>\n",
       "      <td>[(expanded, 270.0), (reuters, 170.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 12:00:00</th>\n",
       "      <td>[(expanded, 270.0), (june, 199.0), (reuters, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 16:00:00</th>\n",
       "      <td>[(expanded, 180.0), (reuters, 123.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 20:00:00</th>\n",
       "      <td>[(expanded, 360.0), (june, 192.0), (reuters, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 00:00:00</th>\n",
       "      <td>[(expanded, 135.0), (june, 50.0), (reuters, 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 04:00:00</th>\n",
       "      <td>[(expanded, 134.0), (reuters, 54.0), (june, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 08:00:00</th>\n",
       "      <td>[(expanded, 271.0), (reuters, 186.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 12:00:00</th>\n",
       "      <td>[(expanded, 359.0), (reuters, 153.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 16:00:00</th>\n",
       "      <td>[(expanded, 384.0), (struggling, 168.0), (rend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 20:00:00</th>\n",
       "      <td>[(expanded, 496.0), (june, 239.0), (reuters, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-03 00:00:00</th>\n",
       "      <td>[(expanded, 3065.0), (reuters, 747.0), (june, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-03 04:00:00</th>\n",
       "      <td>[(expanded, 956.0), (reuters, 163.0), (june, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              trending\n",
       "DATE_TIME                                                             \n",
       "2013-06-01 00:00:00  [(expanded, 364.0), (reuters, 229.0), (june, 1...\n",
       "2013-06-01 04:00:00  [(reuters, 105.0), (money, 72.0), (north, 63.0...\n",
       "2013-06-01 08:00:00  [(expanded, 270.0), (reuters, 170.0), (june, 1...\n",
       "2013-06-01 12:00:00  [(expanded, 270.0), (june, 199.0), (reuters, 1...\n",
       "2013-06-01 16:00:00  [(expanded, 180.0), (reuters, 123.0), (june, 1...\n",
       "2013-06-01 20:00:00  [(expanded, 360.0), (june, 192.0), (reuters, 1...\n",
       "2013-06-02 00:00:00  [(expanded, 135.0), (june, 50.0), (reuters, 41...\n",
       "2013-06-02 04:00:00  [(expanded, 134.0), (reuters, 54.0), (june, 36...\n",
       "2013-06-02 08:00:00  [(expanded, 271.0), (reuters, 186.0), (june, 1...\n",
       "2013-06-02 12:00:00  [(expanded, 359.0), (reuters, 153.0), (june, 1...\n",
       "2013-06-02 16:00:00  [(expanded, 384.0), (struggling, 168.0), (rend...\n",
       "2013-06-02 20:00:00  [(expanded, 496.0), (june, 239.0), (reuters, 1...\n",
       "2013-06-03 00:00:00  [(expanded, 3065.0), (reuters, 747.0), (june, ...\n",
       "2013-06-03 04:00:00  [(expanded, 956.0), (reuters, 163.0), (june, 1..."
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_pd.resample('4h').agg({'trending': calc_freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-01 00:00:00</th>\n",
       "      <td>[(expanded, 409.0), (reuters, 334.0), (june, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 08:00:00</th>\n",
       "      <td>[(expanded, 540.0), (reuters, 315.0), (june, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01 16:00:00</th>\n",
       "      <td>[(expanded, 540.0), (june, 314.0), (reuters, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 00:00:00</th>\n",
       "      <td>[(expanded, 269.0), (reuters, 95.0), (june, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 08:00:00</th>\n",
       "      <td>[(expanded, 630.0), (reuters, 339.0), (june, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02 16:00:00</th>\n",
       "      <td>[(expanded, 880.0), (june, 352.0), (reuters, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-03 00:00:00</th>\n",
       "      <td>[(expanded, 4021.0), (reuters, 910.0), (june, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              trending\n",
       "DATE_TIME                                                             \n",
       "2013-06-01 00:00:00  [(expanded, 409.0), (reuters, 334.0), (june, 1...\n",
       "2013-06-01 08:00:00  [(expanded, 540.0), (reuters, 315.0), (june, 3...\n",
       "2013-06-01 16:00:00  [(expanded, 540.0), (june, 314.0), (reuters, 2...\n",
       "2013-06-02 00:00:00  [(expanded, 269.0), (reuters, 95.0), (june, 86...\n",
       "2013-06-02 08:00:00  [(expanded, 630.0), (reuters, 339.0), (june, 2...\n",
       "2013-06-02 16:00:00  [(expanded, 880.0), (june, 352.0), (reuters, 3...\n",
       "2013-06-03 00:00:00  [(expanded, 4021.0), (reuters, 910.0), (june, ..."
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_pd.resample('8h').agg({'trending': calc_freq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>[(expanded, 1489.0), (reuters, 879.0), (june, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-02</th>\n",
       "      <td>[(expanded, 1779.0), (reuters, 774.0), (june, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-03</th>\n",
       "      <td>[(expanded, 4021.0), (reuters, 910.0), (june, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     trending\n",
       "DATE_TIME                                                    \n",
       "2013-06-01  [(expanded, 1489.0), (reuters, 879.0), (june, ...\n",
       "2013-06-02  [(expanded, 1779.0), (reuters, 774.0), (june, ...\n",
       "2013-06-03  [(expanded, 4021.0), (reuters, 910.0), (june, ..."
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_pd.resample('1d').agg({'trending': calc_freq})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can predict that the text content is talking bout <b>reuters</b> <b>expanded</b> in <b>june</b> ...\n",
    "- Actually, this is not just basic NLP technique, we can even build something more advanced like LDA - Topic Model or Word2Vector - Sentiment Analysis ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
